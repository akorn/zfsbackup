#!/bin/zsh
EXPIRE_DEFAULT="now + 3 days"
EXPIRE_FAILED="$EXPIRE_DEFAULT"
EXPIRE_YEARLY="now + 6 years"
EXPIRE_MONTHLY="now + 1 year"
EXPIRE_WEEKLY="now + 2 months"
EXPIRE_DAILY="now + 1 week"
SCHEDULE_ATJOB=1
PATH_TO_REMOVESNAP=/var/lib/svn-checkout/misc-scripts/zfsbackup/server/remove-snapshot-if-allowed
NAMEPREFIX_DEFAULT=extra # will be part of snapshot name
MINSIZE=0
MININODES=7
IMAGE_DEFAULT="zfsbackup-NAMEPREFIX-%Y-%m-%d-%H%M"
SYNC_LOCK=/run/lock/zfsbackup.make-snapshot.sync.lock
SYNC_OR_SLEEP=sleep		# whether to try invoking sync(8) to cause the 'lrefer' property of newly written filesystems to settle, or just sleep; on busy servers, sleep is probably preferable
MAX_SLEEP=$[$(</sys/module/zfs/parameters/zfs_txg_timeout)*2]	# the maximum amount of time to sleep when SYNC_OR_SLEEP is set to 'sleep'; the default relies on a possible linuxism
MAX_PARALLEL_SNAPSHOTS=4	# how many zfs snapshot operations should we allow to run in parallel? You can try tuning this if you find that too many snapshot requests piling up causes slowdowns. It's not guaranteed that reducing or increasing parallelism helps, but it might. If set to less than 1, there is no limit.
SNAPSHOT_LOCK=/run/lock/zfsbackup.make-snapshot.snapshot.lock	# will get a numeric suffix for each slot specified by MAX_PARALLEL_SNAPSHOTS

USE_SYSLOG=1
DEFAULT_FUNCTIONS=/usr/local/share/zfsbackup/functions.zsh

. $DEFAULT_FUNCTIONS
[[ -r /etc/zfsbackup/server.conf ]] && . /etc/zfsbackup/server.conf
[[ -r /etc/zfsbackup/${0:t}.conf ]] && . /etc/zfsbackup/${0:t}.conf

me="${0:t}[rsync$RSYNC_PID]"

# The following function can be overridden in the config as well as by
# supplying a /etc/zfsbackup/server.d/$RSYNC_MODULE_NAME script that takes
# "expires" or "nameprefix" as its first argument. The 2nd argument is 1 if
# the backup was successful and 0 if it was not.
#
# The default assumes that the first successful backup created in a year is
# yearly; the first successful backup created in a month is monthly; the
# first backup created in a week is weekly; and the first backup created on
# a day is daily.
#
# (If several backups are taken on the same day, the first may end up being
# yearly, the 2nd monthly, the 3rd weekly and the 4th daily.)
#
# Subsequent daily backups will get a suffix of $NAMEPREFIX_DEFAULT (which
# defaults to "extra").
#
# Unsuccessful backups get a suffix of "failed" and expire in 3 days
# ($EXPIRE_FAILED).
#
# By default,
# * yearly backups expire in 6 years;
# * monthly backups expire in 1 year;
# * weekly backups expire in 2 months;
# * daily backups expire in 1 week;
# * extra backups expire in 3 days ($EXPIRE_DEFAULT)

function expire_rule() {
	[[ -x /etc/zfsbackup/server.d/$RSYNC_MODULE_NAME ]] && {
		expires=$(/etc/zfsbackup/server.d/$RSYNC_MODULE_NAME expires $successful)
		nameprefix=$(/etc/zfsbackup/server.d/$RSYNC_MODULE_NAME	nameprefix $successful)
		return 0
	}
	[[ "$successful" = "0" ]] && {
		expires="$(date +%s --date "$EXPIRE_FAILED")"
		nameprefix=failed
		return 0
	}
	pushd "$RSYNC_MODULE_PATH/.zfs/snapshot"
	is_first_yearly && {
		expires="$(date +%s --date "$EXPIRE_YEARLY")"
		nameprefix=yearly
		popd; return 0
	}
	is_first_monthly && {
		expires="$(date +%s --date "$EXPIRE_MONTHLY")"
		nameprefix=monthly
		popd; return 0
	}
	is_first_weekly && {
		expires="$(date +%s --date "$EXPIRE_WEEKLY")"
		nameprefix=weekly-$isoweekyear-$week
		popd; return 0
	}
	is_first_daily && {
		expires="$(date +%s --date "$EXPIRE_DAILY")"
		nameprefix=daily
		popd; return 0
	}
	nameprefix="$NAMEPREFIX_DEFAULT"
	expires="$(date +%s --date "$EXPIRE_DEFAULT")"
	popd; return 0
}

function construct_snapshot_name() {
	local name
	local suffix
	name="$origin" # Must begin with this
	suffix="$(zfs get -Hp -o value $PROPPREFIX:image-default "$origin")"
	[[ "$suffix" = "-" ]] && suffix="$IMAGE_DEFAULT"
	suffix=${suffix/NAMEPREFIX/$nameprefix}
	suffix="$(strftime "$suffix" $starttime)"
	echo "$name@$suffix"
}

function is_first_yearly() {
	pattern="^${IMAGE_DEFAULT/NAMEPREFIX*/yearly-$year-}"
	ls -1 | grep -q "$pattern" && return 1
	return 0
}

function is_first_monthly() {
	pattern="^${IMAGE_DEFAULT/NAMEPREFIX*/monthly-$year-$month-}"
	ls -1 | grep -q "$pattern" && return 1
	return 0
}

function is_first_weekly() {
	pattern="^${IMAGE_DEFAULT/NAMEPREFIX*/weekly-$isoweekyear-$week-}"
	ls -1 | grep -q "$pattern" && return 1
	return 0
}

function is_first_daily() {
	pattern="^${IMAGE_DEFAULT/NAMEPREFIX*/daily-$year-$month-$day-}"
	ls -1 | grep -q "$pattern" && return 1
	return 0
}

[[ -n $USER_FUNCTIONS ]] && [[ -r $USER_FUNCTIONS ]] && . $USER_FUNCTIONS	# allow user functions to override default functions

# Get current date and time; we're not currently using every variable
zmodload zsh/datetime
zmodload zsh/system
starttime=$EPOCHSECONDS
strftime      "%Y-%m-%d %Y   %m    %d  %G          %V   %j        %u        %H   %M" $starttime \
	| read fulldate year month day isoweekyear week dayofyear dayofweek hour minute

[[ -r /etc/zfsbackup/server.conf ]] && . /etc/zfsbackup/server.conf

[[ -z "$RSYNC_MODULE_PATH" ]] && die "RSYNC_MODULE_PATH is unset. Exiting."
[[ -z "$RSYNC_MODULE_NAME" ]] && log warning "WTF. RSYNC_MODULE_NAME is unset. Continuing regardless, but this should not happen."

mountpoint -q "$RSYNC_MODULE_PATH" || die "$RSYNC_MODULE_PATH is not a mountpoint. This is not supported."

df --portability -t zfs "$RSYNC_MODULE_PATH" >/dev/null 2>/dev/null || die "$RSYNC_MODULE_PATH is not zfs. This is not supported."

# Obtain dataset name
df --portability -t zfs "$RSYNC_MODULE_PATH" | tail -n 1 | read origin rest	# TODO: use findmnt instead

# Construct snapshot name and properties
unset properties
partial=0
minsize=$(zfs get -Hp -o value ${PROPPREFIX}:minsize "$origin")
[[ "$minsize" = "-" ]] && minsize=$MINSIZE
mininodes=$(zfs get -Hp -o value ${PROPPREFIX}:mininodes "$origin")
[[ "$mininodes" = "-" ]] && mininodes=$MININODES

# Originally, this script tried to use sync -f to unconditionally sync the fs pointed to by RSYNC_MODULE_PATH.
# Unfortunately, if many such syncs piled up they could take an hour or more to finish.
# So in the next iteration, the following optimization was born:
# 1. if we pass the minsize heuristics check without syncing, skip the sync entirely.
# 2. if we don't, try to obtain a lock on SYNC_LOCK. If we can, run sync while holding the lock.
# 3. if we can't, some other thread is already running the sync. We wait for it to finish, then check the minsize heuristic again.
# 4. if we still fail it, it might be possible the previous sync got called too early and didn't sync our changes (dubious, but maybe), so we keep trying until either another sync finishes or a sync(8) we call ourselves finishes.
# This was still unsatisfactory as on a busy server, the single sync(8) we invoked could still take a very long time to finish and it held up 'zfs snapshot' and 'zfs destroy' operations as well, which is why the SYNC_OR_SLEEP tunable was introduced and defaults to 'sleep'.

if [[ $SYNC_OR_SLEEP = sync ]]; then
	tried_sync=0
	sync_attempts=0
	while ! ((tried_sync)) && ((sync_attempts < 2)); do
		actualsize="$(zfs get -Hp -o value lrefer "$origin")"
		df --portability -i "$RSYNC_MODULE_PATH" | tail -n 1 | read foo foo actualinodes foo
		if [[ "$minsize" -gt 0 ]]; then
			if [[ "$actualsize" -lt "$minsize" ]] && ! ((tried_sync)); then
				# maybe we just need to sync for the lrefer value to settle; since sync is expensive, we don't do it unless it seems necessary
				: >>$SYNC_LOCK
				log debug "Actual size of $RSYNC_MODULE_PATH appears to be $actualsize, less than $minsize. Trying to sync() to force zfs to update metadata."
				if zsystem flock -f lockfd -t 0 $SYNC_LOCK 2>/dev/null; then		# if we can't obtain this lock, another thread is already calling sync(); we'll just wait for it to finish.
					tried_sync=1
					sync
					zsystem flock -u lockfd
				else
					zsystem flock -f lockfd $SYNC_LOCK	# wait for the lock; if we get it, it means the sync(8) invoked by the other process finished
					zsystem flock -u $lockfd		# we can release it immediately; we just had to wait for the other sync(8)
					((sync_attempts++))			# we'll try this at most twice
				fi
			else
				log debug "Actual size of $RSYNC_MODULE_PATH is $actualsize, at least $minsize. Skipping unnecessary sync(8)."
				break
			fi
		else
			break
		fi
		if ((tried_sync)) || ((sync_attempts >= 2)); then
			log warning "Actual size of $RSYNC_MODULE_PATH is $actualsize, less than $minsize. Setting partial=1."
			partial=1
		fi
	done
else	# anything that's not 'sync' is taken to mean 'sleep'
	slept_secs=0
	actualsize="$(zfs get -Hp -o value lrefer "$origin")"
	df --portability -i "$RSYNC_MODULE_PATH" | tail -n 1 | read foo foo actualinodes foo
	while ((slept_secs < MAX_SLEEP)) && [[ "$minsize" -gt 0 ]] && [[ "$actualsize" -lt "$minsize" ]]; do
		sleep 1
		((slept_secs++))
		actualsize="$(zfs get -Hp -o value lrefer "$origin")"
		df --portability -i "$RSYNC_MODULE_PATH" | tail -n 1 | read foo foo actualinodes foo
	done
	if [[ "$actualsize" -ge "$minsize" ]]; then
		log debug "Actual size of $RSYNC_MODULE_PATH is $actualsize, at least $minsize. I had to sleep $slept_secs seconds for the 'lrefer' property of ${(qq)origin} to settle."
	else
		log warning "Actual size of $RSYNC_MODULE_PATH is $actualsize, less than $minsize, despite waiting $slept_secs seconds for the 'lrefer' property of ${(qq)origin} to settle. Setting partial=1."
		partial=1
	fi
fi

if [[ "$mininodes" -gt 7 ]]; then
	if [[ "$actualinodes" -lt "$mininodes" ]]; then
		log warning "Actual inodes of $RSYNC_MODULE_PATH is $actualinodes, less than $mininodes. Setting partial=1."
		partial=1
	fi
fi
[[ "$partial" = "1" ]] && properties=($properties -o ${PROPPREFIX}:partial=true) || properties=($properties -o ${PROPPREFIX}:partial=false)
if [[ "$partial" = "0" ]] && [[ "$RSYNC_EXIT_STATUS" = "0" ]]; then
	properties=($properties -o ${PROPPREFIX}:successful=true)
	successful=1
else
	properties=($properties -o ${PROPPREFIX}:successful=false)
	successful=0
fi
properties=($properties -o ${PROPPREFIX}:rsync_exit_status="$RSYNC_EXIT_STATUS")
properties=($properties -o ${PROPPREFIX}:rsync_host_addr="$RSYNC_HOST_ADDR")
properties=($properties -o ${PROPPREFIX}:rsync_host_name="$RSYNC_HOST_NAME")
properties=($properties -o ${PROPPREFIX}:rsync_user_name="$RSYNC_USER_NAME")

expire_rule # sets $nameprefix and $expires
snapname=$(construct_snapshot_name)
expires_readable="$(strftime "%Y-%m-%d %H:%M:%S" $expires)"

properties=($properties -o ${PROPPREFIX}:expires="$expires")
properties=($properties -o ${PROPPREFIX}:expires-readable="$expires_readable")

log notice "transfer from $RSYNC_USER_NAME@${RSYNC_HOST_NAME}[$RSYNC_HOST_ADDR] to [$RSYNC_MODULE_NAME] ($RSYNC_MODULE_PATH) finished (exit status $RSYNC_EXIT_STATUS)."
# Let's try to reduce i/o load and/or kernel lock contention by doing a limited number of snapshots at a time.

if ((MAX_PARALLEL_SNAPSHOTS < 1)); then	# no limit configured
	log info "Running zfs snapshot $@ $properties[@] $snapname"
	zfs snapshot $@ $properties[@] "$snapname" >&2
else
	SNAPSHOT_LOCK=${SNAPSHOT_LOCK:-/run/lock/zfsbackup.make-snapshot.snapshot.lock}	# give it a sensible value in case the configuration zeroed it out

	for i in {1..$MAX_PARALLEL_SNAPSHOTS}; do : >>$SNAPSHOT_LOCK.$i; done		# Create the lockfiles
	snapshot_done=0
	while ! ((snapshot_done)); do
		for i in {1..$MAX_PARALLEL_SNAPSHOTS}; do
			if zsystem flock -f lockfd -t 0 $SNAPSHOT_LOCK.$i 2>/dev/null; then
					log info "Running zfs snapshot $@ $properties[@] $snapname (snapshot thread id: $i; max: $MAX_PARALLEL_SNAPSHOTS)"
					zfs snapshot $@ $properties[@] "$snapname" >&2
					zsystem flock -u $lockfd
					snapshot_done=1
					break
			fi
		done
		if ! ((snapshot_done)); then
			log debug "$MAX_PARALLEL_SNAPSHOTS snapshot operations already in progress. Delaying 'zfs snapshot $@ $properties[@] $snapname'."
			sleep 1	# no locks available; wait and retry
		fi
	done
fi

if [[ "$SCHEDULE_ATJOB" = "1" ]]; then
	if ! [[ "$expires" = "never" ]]; then
		cd /
		echo "${(q)PATH_TO_REMOVESNAP}" \"$snapname\" \
			| if ! at -t $(strftime "%Y%m%d%H%M.%S" "$[expires+60]") >&2; then
				log err "Failed to schedule atjob. Maybe at isn't installed?"
			fi
	fi
fi
log notice "${0:t}[$RSYNC_PID]: backup job completed."
